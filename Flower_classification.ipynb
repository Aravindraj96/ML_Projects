{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwvNv228OLqvhMWaPaxuK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindraj27/ML_Projects/blob/main/Flower_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhV7bVaTsf-J"
      },
      "source": [
        "### Image Classification\n",
        "Image classification is basically giving an input image where the image is split in to pixeks anbd based on the values in each pixel its classified among the different classes that are available in the data frame\n",
        "\n",
        "This can be done on a plain vanilla nueral network where the input perceptron count is the same as the number of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eb-EnW1qqXg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2B-mBj4MMA0"
      },
      "source": [
        "### Find Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3-g2QLFMLgH"
      },
      "source": [
        "dataset = pd.read_csv('IrisTrain.csv')\n",
        "dataset.describe()\n",
        "dataset.pop('Id')\n",
        "dataset.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KK5DDnNM7y4"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtsRiCU1NARo"
      },
      "source": [
        "# Sepal Length in cm\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-setosa'].SepalLengthCm, color='green', bins=20)\n",
        "plt.title('Sepal Length Distribution')\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-versicolor'].SepalLengthCm, color='blue', bins=20)\n",
        "plt.title('Sepal Length Distribution')\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(2,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-virginica'].SepalLengthCm, color='violet', bins=20)\n",
        "plt.title('Sepal Length Distribution')\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('Number of flowers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hGUjwe46LGy"
      },
      "source": [
        "# Sepal Width in cm\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-setosa'].SepalWidthCm, color='green', bins=20)\n",
        "plt.title('Sepal Width Distribution')\n",
        "plt.xlabel('Sepal Width')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-versicolor'].SepalWidthCm, color='blue', bins=20)\n",
        "plt.title('Sepal Width Distribution')\n",
        "plt.xlabel('Sepal Width')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(2,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-virginica'].SepalWidthCm, color='violet', bins=20)\n",
        "plt.title('Sepal Width Distribution')\n",
        "plt.xlabel('Sepal Width')\n",
        "plt.ylabel('Number of flowers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7iokxLl8D62"
      },
      "source": [
        "# Petal Length in cm\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-setosa'].PetalLengthCm, color='green', bins=20)\n",
        "plt.title('Petal Length Distribution')\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-versicolor'].PetalLengthCm, color='blue', bins=20)\n",
        "plt.title('Petal Length Distribution')\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(7.5,3.75))\n",
        "plt.subplot(2,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-virginica'].PetalLengthCm, color='violet', bins=20)\n",
        "plt.title('Petal Length Distribution')\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Number of flowers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKv371SG8edT"
      },
      "source": [
        "# Petal Width in cm\n",
        "plt.figure(figsize=(15,7.5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-setosa'].PetalWidthCm, color='green', bins=20)\n",
        "plt.title('Petal Width Distribution')\n",
        "plt.xlabel('Petal Width')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-versicolor'].PetalWidthCm, color='blue', bins=20)\n",
        "plt.title('Petal Width Distribution')\n",
        "plt.xlabel('Petal Width')\n",
        "plt.ylabel('Number of flowers')\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "plt.subplot(2,2,1)\n",
        "plt.hist(dataset[dataset.Species == 'Iris-virginica'].PetalWidthCm, color='violet', bins=20)\n",
        "plt.title('Petal Width Distribution')\n",
        "plt.xlabel('Petal Width')\n",
        "plt.ylabel('Number of flowers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4QQuLEh_QHL"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLwxiNLe_SP4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "dataset['Species'] = le.fit_transform(dataset['Species'])\n",
        "fig,ax = plt.subplots(figsize=(20, 20))\n",
        "sns.heatmap(dataset.corr(), annot=True, cmap='coolwarm', ax=ax, vmin=-1, vmax=1)\n",
        "#sns.heatmap(dataset.corr, annot=True, vmin=-1, vmax=1, center=0, cmap='blue', ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn_uBhIz5kUe"
      },
      "source": [
        "### Conclusions from Heat map\n",
        "* We do not omit the column sepal width because the number of features is already less and sacrificing a column may cause overfitting\n",
        "* The Petal coulmns have a higher weigthage over the Species"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hybn41vWI9eu"
      },
      "source": [
        "fig, axes = plt.subplots (1, 4, figsize = (15,6), sharey = True)\n",
        "sns.boxplot(ax=axes[0], data=dataset, x='Species', y='SepalLengthCm', palette='Set2')\n",
        "sns.boxplot(ax=axes[1], data=dataset, x='Species', y='SepalWidthCm', palette='Set2')\n",
        "sns.boxplot(ax=axes[2], data=dataset, x='Species', y='PetalLengthCm', palette='Set2')\n",
        "sns.boxplot(ax=axes[3], data=dataset, x='Species', y='PetalWidthCm', palette='Set2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpmhuijWJ8zG"
      },
      "source": [
        "CSV_COLUMNS_NAMES=['Id','SepalLength','SepalWidth','PetalLength','PetalWidth','Species']\n",
        "SPECIES = ['Setosa','Versicolor','Virginica']\n",
        "dataset_train = pd.read_csv('IrisTrain.csv', names=CSV_COLUMNS_NAMES, header=0)\n",
        "dataset_test = pd.read_csv('IrisTest.csv', names=CSV_COLUMNS_NAMES, header=0)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "dataset_train['Species'] = le.fit_transform(dataset_train['Species'])\n",
        "print(dataset_train.head)\n",
        "dataset_test['Species'] = le.fit_transform(dataset_test['Species'])\n",
        "dataset_train.pop('Id')\n",
        "dataset_test.pop('Id')\n",
        "y_train = dataset_train.pop('Species')\n",
        "y_test = dataset_test.pop('Species')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKILQX1HqycG"
      },
      "source": [
        "### Input Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwH6p4Nlq2ya"
      },
      "source": [
        "def input_func (trainds, labels, train=True, batch_size=256):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(trainds),labels))\n",
        "  if train:\n",
        "    ds = ds.shuffle(1000).repeat()\n",
        "  return ds.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwBNjyfczDaq"
      },
      "source": [
        "### Feature Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWovmPLGzGdi"
      },
      "source": [
        "feature_columns = []\n",
        "for key in dataset_train.keys():\n",
        "  feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B75S4ip4-g3g"
      },
      "source": [
        "### Building the model.\n",
        "Types of Classifiers.\n",
        "* DNN Classifier\n",
        "* Linear Classifier\n",
        "\n",
        "Since there is no linear relationship between the data and species we go for Deep neural networks classifier.\n",
        "\n",
        "### Deep Neural Network classfier\n",
        "\n",
        "We are going create a simple vanilla nueral network with two hidden layers.\n",
        "* Layer 1 - 30\n",
        "* Layer 2 - 10\n",
        "* Input Layer - 4\n",
        "* Output Layer - 3\n",
        "\n",
        "The Feature columns has four variables and the input for each perceptron is created from the dataset through the input function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmM3TAj4-gTH"
      },
      "source": [
        "classifier_leaky_relu = tf.estimator.DNNClassifier(\n",
        "    feature_columns = feature_columns,\n",
        "    hidden_units = [30, 15],\n",
        "    activation_fn = tf.nn.leaky_relu,\n",
        "    optimizer = 'Adam',\n",
        "    n_classes = 3,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSIP3yZ3EeC8"
      },
      "source": [
        "classifier_relu = tf.estimator.DNNClassifier(\n",
        "    feature_columns = feature_columns,\n",
        "    hidden_units = [30, 15],\n",
        "    optimizer = 'Adam',\n",
        "    n_classes = 3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB6omG7mFBFa"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F6kgQHtFABl"
      },
      "source": [
        "\n",
        "classifier_leaky_relu.train(\n",
        "    input_fn = lambda:input_func(dataset_train, y_train, train=True),\n",
        "    steps=5000\n",
        ")\n",
        "\n",
        "predictions = classifier_leaky_relu.evaluate(\n",
        "    input_fn = lambda:input_func(dataset_test, y_test, train=False)\n",
        ")\n",
        "clear_output()\n",
        "prediction = classifier_leaky_relu.predict(\n",
        "    input_fn = lambda:input_func(dataset_test, y_test, train=False)\n",
        ")\n",
        "for pred_key in prediction:\n",
        "  print (pred_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brq6QLJtRGwW"
      },
      "source": [
        "classifier_relu.train(\n",
        "    input_fn = lambda:input_func(dataset_train, y_train, train=True),\n",
        "    steps=5000\n",
        ")\n",
        "\n",
        "classifier_relu.evaluate(\n",
        "    input_fn = lambda:input_func(dataset_test, y_test, train=False)\n",
        ")\n",
        "prediction = classifier_relu.predict(\n",
        "    input_fn = lambda:input_func(dataset_test, y_test, train=False)\n",
        ")\n",
        "for pred_key in prediction:\n",
        "  print (pred_key)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}